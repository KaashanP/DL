{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J035_DL_LAB_ASSN-8_ii_Keras_Callbacks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNw/mmd9NxCCjrx+rghQkFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaashanP/DL/blob/master/J035_DL_LAB_ASSN_8_ii_Keras_Callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDcn9SoDIesu",
        "colab_type": "text"
      },
      "source": [
        "#Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB6n2qutIexq",
        "colab_type": "text"
      },
      "source": [
        "Deep learning models can take hours, days or even weeks to train.\n",
        "\n",
        "If the run is stopped unexpectedly, you can lose a lot of work.\n",
        "\n",
        "In this post you will discover how you can check-point your deep learning models during training in Python using the Keras library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxKWUAfrIdSx",
        "colab_type": "code",
        "outputId": "a6947961-902b-4370-e90f-bf78710deb51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test), callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.2892 - accuracy: 0.9125 - val_loss: 0.1232 - val_accuracy: 0.9616\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.96160, saving model to weights-improvement-01-0.96.hdf5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1206 - accuracy: 0.9635 - val_loss: 0.1057 - val_accuracy: 0.9663\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.96160 to 0.96630, saving model to weights-improvement-02-0.97.hdf5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0834 - accuracy: 0.9741 - val_loss: 0.0901 - val_accuracy: 0.9719\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.96630 to 0.97190, saving model to weights-improvement-03-0.97.hdf5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0640 - accuracy: 0.9796 - val_loss: 0.0741 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.97190 to 0.97660, saving model to weights-improvement-04-0.98.hdf5\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.0779 - val_accuracy: 0.9768\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.97660 to 0.97680, saving model to weights-improvement-05-0.98.hdf5\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0410 - accuracy: 0.9873 - val_loss: 0.0772 - val_accuracy: 0.9789\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.97680 to 0.97890, saving model to weights-improvement-06-0.98.hdf5\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 0.0894 - val_accuracy: 0.9767\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.97890\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.0833 - val_accuracy: 0.9786\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.97890\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0952 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.97890\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.0918 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.97890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fe8210e0f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGoE1pGCI1Ua",
        "colab_type": "text"
      },
      "source": [
        "#Create checkpoint for storing best model only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EfADbj4I-NY",
        "colab_type": "text"
      },
      "source": [
        "A simpler check-point strategy is to save the model weights to the same file, if and only if the validation accuracy improves.\n",
        "\n",
        "This can be done easily using the same code from above and changing the output filename to be fixed (not include score or epoch information).\n",
        "\n",
        "In this case, model weights are written to the file “weights.best.hdf5” only if the classification accuracy of the model on the validation dataset improves over the best seen so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uBtBqGtIup5",
        "colab_type": "code",
        "outputId": "f096ff09-b0aa-405b-c159-3757c520692b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# checkpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.2892 - accuracy: 0.9115 - val_loss: 0.1608 - val_accuracy: 0.9520\n",
            "Epoch 2/10\n",
            " 2048/60000 [>.............................] - ETA: 5s - loss: 0.1173 - accuracy: 0.9648"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.1206 - accuracy: 0.9635 - val_loss: 0.1053 - val_accuracy: 0.9666\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0837 - accuracy: 0.9746 - val_loss: 0.0986 - val_accuracy: 0.9696\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0629 - accuracy: 0.9804 - val_loss: 0.0974 - val_accuracy: 0.9707\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0510 - accuracy: 0.9837 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0415 - accuracy: 0.9868 - val_loss: 0.0905 - val_accuracy: 0.9756\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.1000 - val_accuracy: 0.9728\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0946 - val_accuracy: 0.9759\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0937 - val_accuracy: 0.9756\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0871 - val_accuracy: 0.9786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fe81fd4deb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSl1MrQjJIOD",
        "colab_type": "text"
      },
      "source": [
        "#Loading a Check-Pointed Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "127PHPDSJJjI",
        "colab_type": "text"
      },
      "source": [
        "After the model is saved , we can use it to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOwkbpvjXs4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras import models\n",
        "#Create new model\n",
        "model_new = models.Sequential()\n",
        "model_new.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model_new.add(Dense(256, activation='elu'))\n",
        "model_new.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_new.load_weights(\"weights.best.hdf5\")\n",
        "\n",
        "# Compile model\n",
        "model_new.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "X_total=np.concatenate((X_train,X_test))\n",
        "y_total=np.concatenate((y_train,y_test))\n",
        "\n",
        "scores = model_new.evaluate(X_total, y_total, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model_new.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6pPnH2fJQHV",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    }
  ]
}